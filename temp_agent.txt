import json
import os
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional

import numpy as np
import pandas as pd
import xgboost as xgb
import yfinance as yf
from stable_baselines3 import PPO


# --- 数据结构定义（与 README 契合） ---
@dataclass
class ModelInput:
    timestamp: datetime
    symbol: str
    timeframe: str
    price: float
    history_candles: List[Dict] | pd.DataFrame
    candle: Dict
    position: int
    bars_held: int
    open_trades: int
    entry_price: float
    daily_pnl: float
    daily_drawdown: float
    equity: float
    balance: float
    meta: Dict


@dataclass
class ModelOutput:
    signal: str  # "BUY" / "SELL" / "HOLD"
    size: float  # 0.0 ~ 1.0
    sl: Optional[float]
    tp: Optional[float]
    confidence: float  # 0.0 ~ 1.0
    tag: str
    extra: Dict


class TradingAgent:
    """
    三道防线：
    1) Dead Zone (XGB 信号死区) -> 防止 Always-In
    2) Regime Filter (EMA200 熊市禁多，可配置)
    3) RL 决策 (PPO)，特征屏蔽：仅末两维保留信号
    """

    def __init__(self, bundle_dir: str, dead_zone: Optional[float] = None):
        base = Path(bundle_dir).resolve()
        self.bundle_dir = Path(__file__).resolve().parent if not base.exists() else base
        self.base_dir = str(self.bundle_dir)
        self.risk_cfg = self._load_risk_cfg()
        # 优先使用传入 dead_zone，否则回落到配置文件
        cfg_dead_zone = self.risk_cfg.get("signal_filters", {}).get(
            "dead_zone_threshold", 0.60
        )
        self.dead_zone = cfg_dead_zone if dead_zone is None else dead_zone
        trend_cfg = self.risk_cfg.get("trend_filters", {})
        self.use_trend_filter = bool(trend_cfg.get("enabled", True))
        self.ema_period = int(trend_cfg.get("period", 200))
        self.regime_rules = trend_cfg.get("regime_rules", {})
        self.feature_schema = self._load_feature_schema()
        self.feature_stats = self._load_feature_stats()
        self.feature_dim = int(self.feature_schema.get("feature_dim", 39))
        self.history_window = int(self.feature_schema.get("history_window_size", 300))
        
        # Volatility Settings
        self.vol_cfg = self.risk_cfg.get("volatility_settings", {})
        self.use_atr = self.vol_cfg.get("use_atr_sl", False)
        self.atr_period = int(self.vol_cfg.get("atr_period", 14))
        self.sl_mult = float(self.vol_cfg.get("sl_multiplier", 1.5))
        self.tp_mult = float(self.vol_cfg.get("tp_multiplier", 3.0))
        
        self._yf_cache: Dict[str, pd.Series] = {}

        # 模型加载
        self.ppo = PPO.load(self.bundle_dir / "models" / "ppo_best_xauusd.zip")
        self.xgb_up = xgb.Booster()
        self.xgb_up.load_model(str(self.bundle_dir / "models" / "xgb_up.json"))
        self.xgb_down = xgb.Booster()
        self.xgb_down.load_model(str(self.bundle_dir / "models" / "xgb_down.json"))

        print(f"[Agent] Loaded PPO + XGB from {self.bundle_dir}")
        print(
            f"[Agent] Risk Controls -> DeadZone={self.dead_zone}, "
            f"TrendFilter={'ON' if self.use_trend_filter else 'OFF'}(EMA{self.ema_period})"
        )

    # ---------------------- 公共接口 ----------------------
    def predict_from_input(self, model_input: ModelInput) -> ModelOutput:
        df_hist = self._to_dataframe(model_input.history_candles)
        if df_hist.empty:
            return ModelOutput("HOLD", 0.0, None, None, 0.0, "NoData", {})
        if len(df_hist) < max(self.history_window, self.ema_period):
            return ModelOutput(
                "HOLD", 0.0, None, None, 0.0, "Cold_Start_Data_Not_Ready", {}
            )

        # 1) 计算基本行情量化
        ema_val = self._ema(df_hist["close"], self.ema_period)
        current_price = float(model_input.price)

        # 2) 生成特征并做 XGB 推理
        feat_row = self._compute_features(df_hist)
        
        # XGBoost 仅接受 36 个特征，需移除多余的 3 个 (wti_close_ret, gld_close, gld_close_ret)
        # 假设 36 个特征是原始 35 个 + wti_close
        xgb_cols = [c for c in feat_row.columns if c not in ['wti_close_ret', 'gld_close', 'gld_close_ret']]
        feat_row_xgb = feat_row[xgb_cols]
        
        dmat = xgb.DMatrix(feat_row_xgb)
        p_up = float(self.xgb_up.predict(dmat)[0])
        p_down = float(self.xgb_down.predict(dmat)[0])

        # 3) Dead Zone：信号弱则强制空仓
        if p_up < self.dead_zone and p_down < self.dead_zone:
            return ModelOutput(
                "HOLD",
                0.0,
                None,
                None,
                1.0 - self.dead_zone,
                f"DeadZone(thr={self.dead_zone:.2f})",
                {"p_up": p_up, "p_down": p_down, "ema": ema_val},
            )

        # 4) Regime Filter：熊市禁多（可扩展禁空）
        allow_long = True
        allow_short = True
        regime_msg = "Neutral"
        if self.use_trend_filter and ema_val is not None:
            if current_price < ema_val:
                if self.regime_rules.get("bear_market") == "block_long":
                    allow_long = False
                    regime_msg = "Bear_NoLong"
            else:
                regime_msg = "Bull"

        # 5) 构造 RL 观测（特征屏蔽：仅末两维保留信号）
        masked_len = max(self.feature_dim - 2, 0)
        obs = np.zeros(self.feature_dim, dtype=np.float32)
        if masked_len > 0:
            obs[:masked_len] = 0.0
        obs[-2] = p_up
        obs[-1] = p_down
        assert len(obs) == self.feature_dim, "Obs dim mismatch"

        action, _ = self.ppo.predict(obs, deterministic=True)

        # 6) 最终裁决
        final_signal = "HOLD"
        tag = "RL_Hold"
        sl_price = None
        tp_price = None
        
        # Calculate Dynamic Risk Parameters
        sl_dist = 5.0   # Default 500 pips
        tp_dist = 10.0  # Default 1000 pips
        
        if self.use_atr and len(df_hist) > self.atr_period + 1:
            try:
                high = df_hist['high']
                low = df_hist['low']
                close = df_hist['close']
                prev_close = close.shift(1)
                tr1 = high - low
                tr2 = (high - prev_close).abs()
                tr3 = (low - prev_close).abs()
                tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
                atr_val = tr.rolling(window=self.atr_period).mean().iloc[-1]
                
                if atr_val > 0:
                    sl_dist = atr_val * self.sl_mult
                    tp_dist = atr_val * self.tp_mult
            except Exception as e:
                print(f"[Agent] ATR calc failed: {e}")

        if action == 1:
            if allow_long:
                final_signal = "BUY"
                tag = f"RL_Buy({p_up:.2f})"
                sl_price = current_price - sl_dist
                tp_price = current_price + tp_dist
            else:
                tag = "Regime_Block_Long"
        elif action == 2:
            if allow_short:
                final_signal = "SELL"
                tag = f"RL_Sell({p_down:.2f})"
                sl_price = current_price + sl_dist
                tp_price = current_price - tp_dist
            else:
                tag = "Regime_Block_Short"

        confidence = max(p_up, p_down)
        return ModelOutput(
            final_signal,
            1.0 if final_signal != "HOLD" else 0.0,
            sl_price,
            tp_price,
            confidence,
            tag,
            {
                "p_up": p_up,
                "p_down": p_down,
                "ema": ema_val,
                "allow_long": allow_long,
                "allow_short": allow_short,
                "raw_action": int(action),
                "regime": regime_msg,
            },
        )

    # ---------------------- 内部工具 ----------------------
    def _load_risk_cfg(self) -> Dict:
        risk_path = self.bundle_dir / "risk_manager.json"
        if risk_path.exists():
            try:
                cfg = json.loads(risk_path.read_text(encoding="utf-8"))
            except Exception as exc:  # noqa: BLE001
                print(
                    f"[Warning] Failed to load risk_manager.json, fallback to defaults. Error: {exc}"
                )
                cfg = {}
        else:
            print("[Warning] risk_manager.json not found, fallback to defaults.")
            cfg = {}

        # 递归安全取值，填充缺省
        signal_cfg = cfg.get("signal_filters", {})
        if "dead_zone_threshold" not in signal_cfg:
            print("[Warning] signal_filters.dead_zone_threshold missing, use 0.60")
            signal_cfg["dead_zone_threshold"] = 0.60
        trend_cfg = cfg.get("trend_filters", {})
        if "enabled" not in trend_cfg:
            print("[Warning] trend_filters.enabled missing, use True")
            trend_cfg["enabled"] = True
        if "period" not in trend_cfg:
            print("[Warning] trend_filters.period missing, use 200")
            trend_cfg["period"] = 200
        if "regime_rules" not in trend_cfg:
            trend_cfg["regime_rules"] = {}

        cfg["signal_filters"] = signal_cfg
        cfg["trend_filters"] = trend_cfg
        return cfg

    def _load_feature_schema(self) -> Dict:
        schema_path = self.bundle_dir / "feature_schema.json"
        if schema_path.exists():
            return json.loads(schema_path.read_text())
        return {"feature_dim": 39}

    def _load_feature_stats(self) -> Optional[Dict[str, Dict[str, float]]]:
        stats_path = self.bundle_dir / "feature_stats.json"
        if stats_path.exists():
            try:
                return json.loads(stats_path.read_text())
            except Exception as exc:  # noqa: BLE001
                print(f"[Warning] Failed to load feature_stats.json: {exc}")
        return None

    def _to_dataframe(self, history) -> pd.DataFrame:
        if isinstance(history, pd.DataFrame):
            return history.copy()
        return pd.DataFrame(history)

    def _ema(self, series: pd.Series, window: int) -> Optional[float]:
        if len(series) < window:
            return None
        return float(series.ewm(span=window, adjust=False).mean().iloc[-1])

    def _compute_features(self, df_hist: pd.DataFrame) -> pd.DataFrame:
        """
        占位：此处应复刻训练时的特征工程。
        当前实现：若缺列则自动在本地计算核心 TA/时间特征，并对齐 schema 顺序。
        若宏观列缺失则填 0，并打印一次警告。
        """
        if df_hist.empty:
            raise ValueError("history_candles is empty")
        expected_cols = self.feature_schema.get("feature_names") or []
        if not expected_cols:
            raise ValueError("feature_schema missing 'feature_names'")

        df_feat = self._ensure_features(df_hist.copy(), expected_cols)

        # 应用训练时统计量进行标准化（存在则使用）
        if self.feature_stats:
            for col, stat in self.feature_stats.items():
                if col in df_feat.columns:
                    df_feat[col] = (df_feat[col] - stat.get("mean", 0.0)) / (
                        stat.get("std", 1.0) + 1e-8
                    )

        last_row = df_feat.loc[:, expected_cols].iloc[[-1]].astype(np.float32)
        return last_row

    def _fetch_yf_series(
        self, ticker: str, start: pd.Timestamp, end: pd.Timestamp
    ) -> Optional[pd.Series]:
        """下载 yfinance 收盘价并缓存。"""
        if ticker in self._yf_cache:
            return self._yf_cache[ticker]
        try:
            data = yf.download(
                ticker,
                start=start.date(),
                end=end.date() + pd.Timedelta(days=1),
                progress=False,
                auto_adjust=False,
            )
            if data.empty or "Close" not in data:
                print(f"[Warning] yfinance returned empty for {ticker}")
                return None
            series = data["Close"].copy()
            series.index = pd.to_datetime(series.index)
            self._yf_cache[ticker] = series
            return series
        except Exception as exc:  # noqa: BLE001
            print(f"[Warning] yfinance download failed for {ticker}: {exc}")
            return None

    def _ensure_features(
        self, df: pd.DataFrame, expected_cols: List[str]
    ) -> pd.DataFrame:
        """生成/补齐必需特征；宏观列缺失时填 0 并告警一次。"""
        if "datetime" not in df.columns:
            raise ValueError("history_candles must include 'datetime'")
        df["datetime"] = pd.to_datetime(df["datetime"])
        df = df.sort_values("datetime").reset_index(drop=True)

        # 基础价量
        for c in ["open", "high", "low", "close", "volume"]:
            if c not in df.columns:
                raise ValueError(f"history_candles missing base column '{c}'")

        # 收益/对数收益
        df["log_ret"] = np.log(df["close"] / df["close"].shift()).replace(
            [np.inf, -np.inf], np.nan
        )
        for c in ["open", "high", "low", "close"]:
            df[f"{c}_ret"] = np.log(df[c] / df[c].shift()).replace(
                [np.inf, -np.inf], np.nan
            )

        # 时间特征
        df["hour"] = df["datetime"].dt.hour
        df["hour_sin"] = np.sin(2 * np.pi * df["hour"] / 24.0)
        df["hour_cos"] = np.cos(2 * np.pi * df["hour"] / 24.0)
        df["session_state"] = pd.cut(
            df["hour"], bins=[-1, 7, 15, 23], labels=[0, 1, 2]
        ).astype(int)

        # zscore 96
        roll_mean = df["close"].rolling(96).mean()
        roll_std = df["close"].rolling(96).std() + 1e-8
        df["zscore_close"] = (df["close"] - roll_mean) / roll_std
        lr = df["log_ret"]
        lr_mean = lr.rolling(96).mean()
        lr_std = lr.rolling(96).std() + 1e-8
        df["zscore_log_ret"] = (lr - lr_mean) / lr_std

        # MACD
        ema12 = df["close"].ewm(span=12, adjust=False).mean()
        ema26 = df["close"].ewm(span=26, adjust=False).mean()
        df["macd"] = ema12 - ema26
        df["macd_signal"] = df["macd"].ewm(span=9, adjust=False).mean()
        df["macd_hist"] = df["macd"] - df["macd_signal"]

        # RSI 14
        delta = df["close"].diff()
        gain = delta.clip(lower=0)
        loss = -delta.clip(upper=0)
        roll_up = gain.rolling(14).mean()
        roll_down = loss.rolling(14).mean()
        rs = roll_up / (roll_down + 1e-8)
        df["rsi"] = 100 - (100 / (1 + rs))

        # CCI 20
        tp = (df["high"] + df["low"] + df["close"]) / 3
        sma_tp = tp.rolling(20).mean()
        mad_tp = (tp - sma_tp).abs().rolling(20).mean()
        df["cci"] = (tp - sma_tp) / (0.015 * (mad_tp + 1e-8))

        # ATR 14
        high_low = df["high"] - df["low"]
        high_close = (df["high"] - df["close"].shift()).abs()
        low_close = (df["low"] - df["close"].shift()).abs()
        tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)
        df["atr"] = tr.rolling(14).mean()

        # ADX 14
        up_move = df["high"].diff()
        down_move = -df["low"].diff()
        plus_dm = (
            (up_move.where((up_move > down_move) & (up_move > 0), 0.0))
            .ewm(alpha=1 / 14, adjust=False)
            .mean()
        )
        minus_dm = (
            (down_move.where((down_move > up_move) & (down_move > 0), 0.0))
            .ewm(alpha=1 / 14, adjust=False)
            .mean()
        )
        atr_ewm = tr.ewm(alpha=1 / 14, adjust=False).mean()
        plus_di = 100 * (plus_dm / (atr_ewm + 1e-8))
        minus_di = 100 * (minus_dm / (atr_ewm + 1e-8))
        dx = (abs(plus_di - minus_di) / (plus_di + minus_di + 1e-8)) * 100
        df["adx"] = dx.ewm(alpha=1 / 14, adjust=False).mean()

        # 波动率
        df["vol_96"] = df["log_ret"].rolling(96).std()
        df["vol_288"] = df["log_ret"].rolling(288).std()
        df["volatility_ratio"] = df["volume"] / (df["volume"].rolling(96).mean() + 1e-8)

        # 宏观/外盘：缺失则尝试 yfinance 填充，仍缺则填 0 并告警
        macro_cols = [
            "dxy_close",
            "dxy_close_ret",
            "dxy_ret",
            "us10y_price",
            "us10y_price_ret",
            "us10y_price_ret_pct",
            "wti_close",
            "wti_close_ret",
            "gld_close",
            "gld_close_ret",
            "corr_close_dxy",
            "corr_close_us10y",
            "corr_dxy_60",
            "corr_close_us10y_60",
        ]
        missing_macro = [c for c in macro_cols if c not in df.columns]
        if missing_macro:
            start_dt = df["datetime"].min()
            end_dt = df["datetime"].max()
            ticker_map = {
                "dxy_close": "DX-Y.NYB",
                "us10y_price": "^TNX",
                "wti_close": "CL=F",
                "gld_close": "GLD",
            }
            for col, ticker in ticker_map.items():
                if col in df.columns:
                    continue
                series = self._fetch_yf_series(ticker, start_dt, end_dt)
                if series is not None:
                    # 对齐到日期，前向填充
                    ser = (
                        series.resample("D")
                        .last()
                        .reindex(
                            pd.date_range(
                                start=start_dt.floor("D"),
                                end=end_dt.floor("D"),
                                freq="D",
                            )
                        )
                        .ffill()
                    )
                    df[col] = (
                        df["datetime"].dt.floor("D").map(ser.to_dict()).astype(float)
                    )


        # 宏观收益/相关性计算（若原始列存在）
        if "dxy_close" in df.columns:
            df["dxy_close_ret"] = np.log(
                df["dxy_close"] / df["dxy_close"].shift()
            ).replace([np.inf, -np.inf], np.nan)
            df["dxy_ret"] = df["dxy_close_ret"]
        if "us10y_price" in df.columns:
            df["us10y_price_ret"] = np.log(
                df["us10y_price"] / df["us10y_price"].shift()
            ).replace([np.inf, -np.inf], np.nan)
            df["us10y_price_ret_pct"] = (
                df["us10y_price"].pct_change().replace([np.inf, -np.inf], np.nan)
            )
        if "wti_close" in df.columns:
            df["wti_close_ret"] = np.log(
                df["wti_close"] / df["wti_close"].shift()
            ).replace([np.inf, -np.inf], np.nan)
        if "gld_close" in df.columns:
            df["gld_close_ret"] = np.log(
                df["gld_close"] / df["gld_close"].shift()
            ).replace([np.inf, -np.inf], np.nan)

        # 相关性（需列存在）
        if {"close", "dxy_close"}.issubset(df.columns):
            df["corr_dxy_60"] = df["close"].rolling(60).corr(df["dxy_close"])
        if {"close", "us10y_price"}.issubset(df.columns):
            df["corr_close_us10y_60"] = df["close"].rolling(60).corr(df["us10y_price"])

        # Final check for missing macro columns
        still_missing = [c for c in macro_cols if c not in df.columns]
        if still_missing:
            print(
                f"[Warning] missing macro/externals {still_missing}, filling 0 (may drift from training)."
            )
            for c in still_missing:
                df[c] = 0.0

        df = df.drop(columns=["hour"], errors="ignore")
        return df


def load_agent(bundle_dir: str) -> TradingAgent:
    return TradingAgent(bundle_dir=bundle_dir)
